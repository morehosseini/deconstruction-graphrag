{"cells":[{"cell_type":"markdown","metadata":{"id":"HnwpWDZ86mRo"},"source":["# üèóÔ∏è Research Tool: The \"Deconstruction Filter\" (Pilot)\n","\n","**Project:** Circular Economy in Australian Construction  \n","**Objective:** Semantic Pre-processing for Knowledge Graph Extraction\n","\n","## üéØ Strategy: The \"Needle in the Haystack\"\n","We are dealing with large, mixed-topic PDFs (e.g., National Waste Policies). Most of the text in these documents is irrelevant to your specific focus on **structural deconstruction** and **salvage**.\n","\n","If we feed the entire document to the LLM, we risk:\n","1.  **Graph Pollution:** Creating nodes for \"Curbside Recycling\" or \"Landfill Levies\" that clutter your Deconstruction analysis.\n","2.  **Context Dilution:** The LLM might lose the specific nuance of \"disassembly\" amidst general waste management text.\n","3.  **Cost Inefficiency:** Processing thousands of irrelevant tokens.\n","\n","## üõ†Ô∏è The Solution: Semantic Filtering\n","This notebook implements a **Vector-Based Filter** before extraction:\n","1.  **Chunking:** Splits the PDF into analyzeable segments (paragraphs).\n","2.  **Embedding:** Converts text into mathematical vectors using `text-embedding-3-small`.\n","3.  **Similarity Search:** Compares every paragraph against your specific research queries (e.g., \"salvage of timber\", \"selective demolition\").\n","4.  **Filtering:** Discards any text that does not meet a strict relevance threshold.\n","\n","---"],"id":"HnwpWDZ86mRo"},{"cell_type":"markdown","metadata":{"id":"Hqd2fwtQ6mRp"},"source":["### 1. üì¶ Installation & Setup\n","We need `pypdf` for robust PDF parsing, `langchain` for the orchestration, and `faiss-cpu` for the vector similarity search."],"id":"Hqd2fwtQ6mRp"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NFkKpcC6mRq","executionInfo":{"status":"ok","timestamp":1770699855883,"user_tz":-660,"elapsed":6854,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"f24bfbf1-2f54-4312-8f69-ae7cbd80f891"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Libraries installed successfully.\n"]}],"source":["# @title 1. Install Required Libraries (Fixed)\n","# @markdown Run this cell to install the necessary tools.\n","!pip install -q langchain langchain-openai langchain-community langchain-text-splitters pypdf tiktoken faiss-cpu\n","\n","import os\n","import sys\n","from google.colab import drive, userdata\n","\n","print(\"‚úÖ Libraries installed successfully.\")"],"id":"2NFkKpcC6mRq"},{"cell_type":"markdown","metadata":{"id":"3M8sAXbq6mRq"},"source":["### 2. üîë API Connection (Safety Check)\n","This step ensures your OpenAI API key is correctly loaded from Google Colab Secrets.\n","\n","**Instructions:**\n","1. Click the **Key icon** (Secrets) on the left sidebar of Colab.\n","2. Add a new secret named: `OPENAI_API_KEY`\n","3. Paste your actual API key as the value.\n","4. Toggle the \"Notebook access\" switch to **On**."],"id":"3M8sAXbq6mRq"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8JMf21-H6mRq","executionInfo":{"status":"ok","timestamp":1770699603757,"user_tz":-660,"elapsed":19380,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"a3b01780-e3c4-49aa-ebcb-8a6427d5d308"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Success! Model replied: Hello! Yes, I'm ready to help with data extraction. Please provide the details or the specific data you need assistance with, and I'll do my best to assist you.\n"]}],"source":["# @title Test LLM Connection\n","try:\n","    # Retrieve key from Colab Secrets\n","    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n","\n","    from langchain_openai import ChatOpenAI\n","\n","    # Simple test call to verify connection\n","    test_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n","    response = test_llm.invoke(\"Hello, are you ready for data extraction?\")\n","    print(f\"‚úÖ Success! Model replied: {response.content}\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Error: {e}\")\n","    print(\"\\n‚ö†Ô∏è Please check that you added 'OPENAI_API_KEY' to the Secrets tab on the left.\")"],"id":"8JMf21-H6mRq"},{"cell_type":"markdown","metadata":{"id":"l2_8XpVK6mRr"},"source":["### 3. üìÇ Mount Google Drive\n","Connect to your Drive to access the PDF files.\n","\n","**Note:** Ensure you define the correct path to your folder in the code block below."],"id":"l2_8XpVK6mRr"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_c40lQu6mRr","executionInfo":{"status":"ok","timestamp":1770699721448,"user_tz":-660,"elapsed":1352,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"d22ed7f9-82f8-40a1-8c8c-8afd905d55c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úÖ Folder found: /content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/Miyuki \n","üìÑ Found 94 PDF files available for processing.\n","   Example: 1.national-waste-and-resource-recovery-report-2024.pdf\n"]}],"source":["# @title Mount Drive & Set Path\n","drive.mount('/content/drive')\n","\n","# ---------------------------------------------------------\n","# üëá UPDATE THIS PATH TO MATCH YOUR DRIVE FOLDER\n","# ---------------------------------------------------------\n","source_folder_path = \"/content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/Miyuki \"\n","\n","if os.path.exists(source_folder_path):\n","    print(f\"‚úÖ Folder found: {source_folder_path}\")\n","    files = [f for f in os.listdir(source_folder_path) if f.endswith('.pdf')]\n","    print(f\"üìÑ Found {len(files)} PDF files available for processing.\")\n","    if len(files) > 0:\n","        print(f\"   Example: {files[0]}\")\n","else:\n","    print(f\"‚ùå Folder not found: {source_folder_path}\")\n","    print(\"‚ö†Ô∏è Please verify the path in your Google Drive.\")"],"id":"0_c40lQu6mRr"},{"cell_type":"markdown","metadata":{"id":"BRrFGpxu6mRr"},"source":["### 4. üß† The Semantic Filter (Pilot Run)\n","This is the core logic. We will test it on **one file** to verify it correctly separates \"Deconstruction\" content from general text.\n","\n","**How it works:**\n","1.  **`filter_queries`**: These are the \"concepts\" we are looking for. I have tuned them to your specific focus on salvage and disassembly.\n","2.  **`similarity_search_with_score`**: Calculates the distance between your PDF paragraphs and these queries.\n","3.  **Threshold**: We filter out any text that isn't highly relevant (Score < 0.5)."],"id":"BRrFGpxu6mRr"},{"cell_type":"code","source":["# @title 4. Run Diagnostic Filter (Fixes Import & Calibrates Threshold)\n","from langchain_community.document_loaders import PyPDFLoader\n","# ‚úÖ FIXED IMPORT: Uses the new library structure\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","import os\n","\n","# ---------------------------------------------------------\n","# üëá ENSURE THIS MATCHES YOUR FILE NAME EXACTLY\n","# ---------------------------------------------------------\n","file_to_test = \"1.national-waste-and-resource-recovery-report-2024.pdf\"\n","\n","# Construct full path\n","full_file_path = os.path.join(source_folder_path, file_to_test)\n","\n","# Define your research focus\n","filter_queries = [\n","    \"building deconstruction and disassembly methods\",\n","    \"salvage of structural materials like timber and steel\",\n","    \"selective demolition practices\",\n","    \"regulatory barriers to deconstruction\",\n","    \"material recovery from demolition\"\n","]\n","\n","if os.path.exists(full_file_path):\n","    print(f\"üîπ Loading: {file_to_test}...\")\n","    loader = PyPDFLoader(full_file_path)\n","    pages = loader.load()\n","\n","    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n","    docs = text_splitter.split_documents(pages)\n","    print(f\"üîπ Split into {len(docs)} chunks.\")\n","\n","    print(\"üîπ Generating embeddings...\")\n","    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n","    vector_db = FAISS.from_documents(docs, embeddings)\n","\n","    print(\"\\nüîé DIAGNOSTIC RESULTS (Top 3 matches per query):\")\n","    print(\"=\"*60)\n","\n","    # We will track the lowest score found to help you set the threshold\n","    min_score_found = 10.0\n","\n","    for query in filter_queries:\n","        print(f\"\\nQuery: '{query}'\")\n","        # Fetch top 3 matches regardless of score\n","        results = vector_db.similarity_search_with_score(query, k=3)\n","\n","        for doc, score in results:\n","            # Update minimum score tracker\n","            if score < min_score_found: min_score_found = score\n","\n","            # Print content only if it's somewhat relevant (e.g. < 1.0)\n","            status = \"‚úÖ KEEP\" if score < 0.5 else \"‚ùå REJECT (Too strict?)\"\n","            print(f\"   Score: {score:.4f} | {status}\")\n","            print(f\"   Snippet: {doc.page_content[:150]}...\")\n","            print(\"-\" * 40)\n","\n","    print(\"=\"*60)\n","    print(f\"üí° RECOMMENDATION:\")\n","    print(f\"The best match had a score of {min_score_found:.4f}.\")\n","    if min_score_found > 0.5:\n","        print(f\"üëâ Change your threshold in the final script to: {min_score_found + 0.1:.2f}\")\n","    else:\n","        print(\"üëâ The threshold of 0.5 is fine, this document just lacks relevant content.\")\n","\n","else:\n","    print(f\"‚ùå File not found: {full_file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLqdKV3N8agt","executionInfo":{"status":"ok","timestamp":1770700012926,"user_tz":-660,"elapsed":19133,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"f5689935-020d-4180-944c-2e80a4762144"},"id":"NLqdKV3N8agt","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["üîπ Loading: 1.national-waste-and-resource-recovery-report-2024.pdf...\n","üîπ Split into 297 chunks.\n","üîπ Generating embeddings...\n","\n","üîé DIAGNOSTIC RESULTS (Top 3 matches per query):\n","============================================================\n","\n","Query: 'building deconstruction and disassembly methods'\n","   Score: 1.1040 | ‚ùå REJECT (Too strict?)\n","   Snippet: Built \n","environment  \n","Guidelines and resources  are emerging  for preventing  waste in the design, operation and \n","deconstruction of buildings and infra...\n","----------------------------------------\n","   Score: 1.1384 | ‚ùå REJECT (Too strict?)\n","   Snippet: refurbished options. Packaging reuse is also a focus, with some established services for \n","business-to-business secondary and tertiary packaging. Enter...\n","----------------------------------------\n","   Score: 1.2735 | ‚ùå REJECT (Too strict?)\n","   Snippet: redirect s wearable clothing back into use (Seamless 2024).  Clothing chain Kathmandu ha s \n","established Kathman-redu, a clothing take -back, repair an...\n","----------------------------------------\n","\n","Query: 'salvage of structural materials like timber and steel'\n","   Score: 0.9652 | ‚ùå REJECT (Too strict?)\n","   Snippet: National waste and resource recovery report 2024  ‚Äì Final Page x \n","Reuse reallocation of products or materials to a new owner or purpose without reproc...\n","----------------------------------------\n","   Score: 1.0127 | ‚ùå REJECT (Too strict?)\n","   Snippet: estimated resource recovery rates were highest for metals (90%) and building and demolition \n","materials (84%). The recovery rate for plastics was the l...\n","----------------------------------------\n","   Score: 1.0710 | ‚ùå REJECT (Too strict?)\n","   Snippet: 7.1 Resource recovery rates, 2022‚Äì23................................ ................................ ...............  38 \n","7.2 Trends in resource reco...\n","----------------------------------------\n","\n","Query: 'selective demolition practices'\n","   Score: 1.1243 | ‚ùå REJECT (Too strict?)\n","   Snippet: This material category includes heavy waste types such as concrete, bricks and rubble and is mostly \n","recorded in the C&D stream. Building and demoliti...\n","----------------------------------------\n","   Score: 1.1674 | ‚ùå REJECT (Too strict?)\n","   Snippet: deliver high quality recovered product at a reasonable \n","cost. In 2018 NSW banned the deposit of the processed \n","organic material on land, and most is n...\n","----------------------------------------\n","   Score: 1.2009 | ‚ùå REJECT (Too strict?)\n","   Snippet: Built \n","environment  \n","Guidelines and resources  are emerging  for preventing  waste in the design, operation and \n","deconstruction of buildings and infra...\n","----------------------------------------\n","\n","Query: 'regulatory barriers to deconstruction'\n","   Score: 1.2883 | ‚ùå REJECT (Too strict?)\n","   Snippet: Built \n","environment  \n","Guidelines and resources  are emerging  for preventing  waste in the design, operation and \n","deconstruction of buildings and infra...\n","----------------------------------------\n","   Score: 1.3427 | ‚ùå REJECT (Too strict?)\n","   Snippet: landfill. Typically, MRFs send waste to landfill when materials are: \n","‚Ä¢ not recyclable and should not have been put in the recycling bin...\n","----------------------------------------\n","   Score: 1.3530 | ‚ùå REJECT (Too strict?)\n","   Snippet: National waste and resource recovery report 2024  ‚Äì Final Page 19 \n","3. Waste prevention  \n","3.1 What is waste prevention? \n","Waste prevention is any delibe...\n","----------------------------------------\n","\n","Query: 'material recovery from demolition'\n","   Score: 0.6940 | ‚ùå REJECT (Too strict?)\n","   Snippet: estimated resource recovery rates were highest for metals (90%) and building and demolition \n","materials (84%). The recovery rate for plastics was the l...\n","----------------------------------------\n","   Score: 0.7605 | ‚ùå REJECT (Too strict?)\n","   Snippet: This material category includes heavy waste types such as concrete, bricks and rubble and is mostly \n","recorded in the C&D stream. Building and demoliti...\n","----------------------------------------\n","   Score: 0.8483 | ‚ùå REJECT (Too strict?)\n","   Snippet: National waste and resource recovery report 2024  ‚Äì Final Page 26 \n","‚Ä¢ improperly presented, for example inside a plastic bag \n","‚Ä¢ too small, for example ...\n","----------------------------------------\n","============================================================\n","üí° RECOMMENDATION:\n","The best match had a score of 0.6940.\n","üëâ Change your threshold in the final script to: 0.79\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}