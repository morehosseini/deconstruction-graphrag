{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"zneuD4Gpuu8O"},"source":["# 6) Presentation Outputs â€” Governance Intelligence Platform\n","\n","**Purpose:** generate publication-quality figures and presentation materials from the\n","backend (Stage 5) demonstrating the platform's capabilities.\n","\n","**Outputs (aligned to paper figure numbering):**\n","1. **Fig 1 â€” System architecture diagram** â€” pipeline from corpus â†’ KG â†’ RAG backend\n","2. **Fig 2 â€” Entityâ€“relationship schema** â€” the 10 entity types + 11 relation types\n","3. **Fig 3 â€” Summary statistics dashboard** â€” corpus and graph composition\n","4. **Fig 4 â€” Governance pathway visualisation** â€” DfD query example with evidence trail\n","5. **Fig 5 â€” Jurisdictional coverage heatmap** â€” instruments Ã— jurisdictions matrix\n","6. **Fig 6 â€” Gap analysis matrix** â€” practices with barriers vs. enabling instruments\n","7. **Fig 7 â€” Demo Q&A cards** â€” formatted queryâ€“answer pairs for slides\n","\n","**Pipeline:**\n","- Â§0 â€” Dependencies & configuration\n","- Â§1 â€” Load backend state + demo answers\n","- Â§2 â€” Fig 1: System architecture diagram\n","- Â§3 â€” Fig 2: Entityâ€“relationship schema diagram\n","- Â§4 â€” Fig 3: Summary statistics dashboard\n","- Â§5 â€” Fig 4: Governance pathway visualisation\n","- Â§6 â€” Fig 5: Jurisdictional coverage heatmap\n","- Â§7 â€” Fig 6: Gap analysis matrix\n","- Â§8 â€” Fig 7: Demo Q&A cards (formatted)\n","- Â§9 â€” Export all figures\n"],"id":"zneuD4Gpuu8O"},{"cell_type":"markdown","metadata":{"id":"x_FhGDomuu8Q"},"source":["## 0) Install dependencies\n","Run once per Colab runtime."],"id":"x_FhGDomuu8Q"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53TI8Hayuu8Q","executionInfo":{"status":"ok","timestamp":1770943957785,"user_tz":-660,"elapsed":6435,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"f0631401-7904-456a-fae7-d87cc52ac787"},"source":["!pip -q install anthropic pandas numpy networkx matplotlib seaborn plotly kaleido pillow\n","\n","import os, json, re, textwrap, pickle\n","from pathlib import Path\n","from collections import defaultdict, Counter\n","\n","import pandas as pd\n","import numpy as np\n","import networkx as nx\n","\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n","import matplotlib.patheffects as pe\n","\n","import seaborn as sns\n","\n","print(\"âœ… Dependencies installed.\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/405.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m399.4/405.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m405.9/405.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/69.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/49.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hâœ… Dependencies installed.\n"]}],"execution_count":2,"id":"53TI8Hayuu8Q"},{"cell_type":"markdown","metadata":{"id":"4LJ15cExuu8R"},"source":["## 1) Configuration + load backend state\n","Reads the backend artefacts from Stage 5 and the cleaned graph from Stage 4."],"id":"4LJ15cExuu8R"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1IZaNAQuu8R","executionInfo":{"status":"ok","timestamp":1770943962389,"user_tz":-660,"elapsed":1191,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"a30345e1-79a2-4a33-e3f7-9cdf6ece87ab"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 1a) Configuration\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","BACKEND_DIR = \"/content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/data_analysis/5_backend\"\n","CLEAN_DIR   = \"/content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/data_analysis/4_kg_cleaned\"\n","OUTPUT_DIR  = \"/content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/data_analysis/6_presentation\"\n","\n","Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n","\n","# â”€â”€ Clean previous outputs to avoid stale/duplicate files â”€â”€\n","import glob\n","old_files = glob.glob(os.path.join(OUTPUT_DIR, \"fig*\")) + glob.glob(os.path.join(OUTPUT_DIR, \"manifest.json\"))\n","if old_files:\n","    for f in old_files:\n","        os.remove(f)\n","    print(f\"ðŸ§¹ Cleaned {len(old_files)} previous output files.\")\n","\n","# Colour palette â€” UoM-inspired professional tones\n","COLOURS = {\n","    \"Instrument\":    \"#094183\",  # UoM dark blue\n","    \"Authority\":     \"#0E6EB8\",  # medium blue\n","    \"Jurisdiction\":  \"#5AAFED\",  # light blue\n","    \"Requirement\":   \"#E87722\",  # orange\n","    \"Practice\":      \"#00843D\",  # green\n","    \"MaterialAsset\": \"#8B6914\",  # gold/brown\n","    \"Stakeholder\":   \"#6B2D5B\",  # plum\n","    \"Barrier\":       \"#C4262E\",  # red\n","    \"Enabler\":       \"#2EAF7D\",  # teal\n","    \"OutcomeMetric\": \"#F2C75C\",  # amber/yellow\n","}\n","\n","ENTITY_ORDER = [\n","    \"Instrument\", \"Authority\", \"Jurisdiction\", \"Requirement\",\n","    \"Practice\", \"MaterialAsset\", \"Stakeholder\",\n","    \"Barrier\", \"Enabler\", \"OutcomeMetric\",\n","]\n","\n","# Figure defaults\n","plt.rcParams.update({\n","    \"figure.dpi\": 200,\n","    \"savefig.dpi\": 300,\n","    \"savefig.bbox\": \"tight\",\n","    \"savefig.pad_inches\": 0.3,\n","    \"font.family\": \"sans-serif\",\n","    \"font.size\": 10,\n","})\n","\n","print(f\"Config loaded. Output: {OUTPUT_DIR}\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ§¹ Cleaned 15 previous output files.\n","Config loaded. Output: /content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/data_analysis/6_presentation\n"]}],"execution_count":3,"id":"A1IZaNAQuu8R"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SsCEeihruu8R","executionInfo":{"status":"ok","timestamp":1770943969687,"user_tz":-660,"elapsed":1559,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"3cd867f4-d87e-452b-8fff-be6d8e10e9af"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 1b) Load backend state + demo answers\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","# Backend state\n","with open(os.path.join(BACKEND_DIR, \"backend_state.pkl\"), \"rb\") as f:\n","    state = pickle.load(f)\n","\n","nodes_df = state[\"nodes_df\"]\n","edges_df = state[\"edges_df\"]\n","triples_df = state[\"triples_df\"]\n","source_chunks = state[\"source_chunks\"]\n","schema = state[\"schema\"]\n","\n","# Demo answers\n","with open(os.path.join(BACKEND_DIR, \"demo_answers.json\")) as f:\n","    demos = json.load(f)\n","\n","# Backend summary\n","with open(os.path.join(BACKEND_DIR, \"backend_summary.json\")) as f:\n","    backend_summary = json.load(f)\n","\n","# Multi-country schema\n","with open(os.path.join(CLEAN_DIR, \"multi_country_schema.json\")) as f:\n","    mc_schema = json.load(f)\n","\n","# Post-load dedup (same fix as Notebook 5)\n","nodes_df[\"name_norm\"] = nodes_df[\"name_norm\"].fillna(nodes_df[\"name\"].str.lower().str.strip())\n","dupes = nodes_df.groupby([\"name_norm\", \"entity_type\"])[\"node_id\"].apply(list)\n","dupes = dupes[dupes.apply(len) > 1]\n","dedup_map = {}\n","for (name_norm, etype), ids in dupes.items():\n","    for other in ids[1:]:\n","        dedup_map[other] = ids[0]\n","if dedup_map:\n","    edges_df[\"subject_id\"] = edges_df[\"subject_id\"].map(lambda x: dedup_map.get(x, x))\n","    edges_df[\"object_id\"] = edges_df[\"object_id\"].map(lambda x: dedup_map.get(x, x))\n","    edges_df = edges_df[edges_df[\"subject_id\"] != edges_df[\"object_id\"]]\n","    nodes_df = nodes_df[~nodes_df[\"node_id\"].isin(dedup_map.keys())]\n","\n","# Build graph\n","G = nx.MultiDiGraph()\n","for _, row in nodes_df.iterrows():\n","    G.add_node(row[\"node_id\"], **{k: v for k, v in row.to_dict().items() if pd.notna(v)})\n","for _, row in edges_df.iterrows():\n","    attrs = {k: v for k, v in row.to_dict().items() if pd.notna(v) and k not in (\"subject_id\", \"object_id\")}\n","    G.add_edge(row[\"subject_id\"], row[\"object_id\"], **attrs)\n","\n","print(f\"Loaded: {len(nodes_df)} nodes, {len(edges_df)} edges, {len(source_chunks)} chunks\")\n","print(f\"Demo answers: {len(demos)} queries\")\n","print(f\"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded: 1641 nodes, 3223 edges, 364 chunks\n","Demo answers: 4 queries\n","Graph: 1641 nodes, 3223 edges\n"]}],"execution_count":4,"id":"SsCEeihruu8R"},{"cell_type":"markdown","metadata":{"id":"cgUo-X_juu8S"},"source":["## 2) System architecture diagram\n","Pipeline diagram showing: Corpus â†’ Chunking â†’ Three-Pass Extraction â†’ Knowledge Graph â†’ RAG Backend â†’ Query Interface.\n","\n","Uses pure matplotlib drawing â€” no external graph libraries needed.\n","\n","**Paper reference: Figure 1.**\n"],"id":"cgUo-X_juu8S"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2BodkWEvuu8S","executionInfo":{"status":"ok","timestamp":1770943975097,"user_tz":-660,"elapsed":1698,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"007e5eb8-6082-4928-e991-84ff4b31648a"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 2) System architecture diagram\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","fig, ax = plt.subplots(figsize=(16, 9))\n","ax.set_xlim(0, 16)\n","ax.set_ylim(0, 9)\n","ax.set_aspect(\"equal\")\n","ax.axis(\"off\")\n","\n","# Title\n","ax.text(8, 8.5, \"Circular Construction Governance Intelligence Platform\",\n","        ha=\"center\", va=\"center\", fontsize=16, fontweight=\"bold\", color=\"#094183\")\n","ax.text(8, 8.05, \"System Architecture\",\n","        ha=\"center\", va=\"center\", fontsize=12, color=\"#555555\")\n","\n","# â”€â”€ Helper functions â”€â”€\n","def draw_box(ax, x, y, w, h, label, sublabel=\"\", colour=\"#094183\", alpha=0.15):\n","    box = FancyBboxPatch((x, y), w, h, boxstyle=\"round,pad=0.15\",\n","                          facecolor=colour, alpha=alpha, edgecolor=colour, linewidth=1.5)\n","    ax.add_patch(box)\n","    if sublabel:\n","        ax.text(x + w/2, y + h/2 + 0.15, label, ha=\"center\", va=\"center\",\n","                fontsize=9, fontweight=\"bold\", color=colour)\n","        ax.text(x + w/2, y + h/2 - 0.2, sublabel, ha=\"center\", va=\"center\",\n","                fontsize=7.5, color=\"#444444\", style=\"italic\")\n","    else:\n","        ax.text(x + w/2, y + h/2, label, ha=\"center\", va=\"center\",\n","                fontsize=9, fontweight=\"bold\", color=colour)\n","\n","def draw_arrow(ax, x1, y1, x2, y2, colour=\"#094183\", label=\"\"):\n","    ax.annotate(\"\", xy=(x2, y2), xytext=(x1, y1),\n","                arrowprops=dict(arrowstyle=\"-|>\", color=colour, lw=1.8))\n","    if label:\n","        mx, my = (x1+x2)/2, (y1+y2)/2 + 0.18\n","        ax.text(mx, my, label, ha=\"center\", va=\"center\", fontsize=7, color=colour,\n","                bbox=dict(boxstyle=\"round,pad=0.1\", facecolor=\"white\",\n","                          edgecolor=\"none\", alpha=0.9))\n","\n","# â”€â”€ Row 1: Data Sources (y ~ 6.3) â”€â”€\n","y1 = 6.3\n","draw_box(ax, 0.5, y1, 2.5, 1.0, \"Policy Corpus\",\n","         f\"{len(set(c.get('source_file','') for c in source_chunks))} AU documents\\n(laws, standards, guides)\", \"#094183\")\n","draw_box(ax, 3.8, y1, 2.5, 1.0, \"UK Corpus\", \"Planned\", \"#AAAAAA\", alpha=0.1)\n","draw_box(ax, 7.1, y1, 2.5, 1.0, \"CA Corpus\", \"Planned\", \"#AAAAAA\", alpha=0.1)\n","\n","# â”€â”€ Row 2: Processing Pipeline (y ~ 4.3) â”€â”€\n","y2 = 4.3\n","draw_box(ax, 0.3, y2, 2.2, 1.0, \"PDF Processing\",\n","         f\"OCR + semantic\\nchunking â†’ {len(source_chunks)} chunks\", \"#0E6EB8\")\n","draw_box(ax, 3.1, y2, 2.2, 1.0, \"Pass 1: Discovery\",\n","         \"Claude Haiku\\n5,703 mentions\", \"#00843D\")\n","draw_box(ax, 5.9, y2, 2.2, 1.0, \"Pass 2: Consolidate\",\n","         \"Embeddings + Sonnet\\n596 merges\", \"#00843D\")\n","draw_box(ax, 8.7, y2, 2.2, 1.0, \"Pass 3: Extract\",\n","         \"Grounded extraction\\nw/ entity registry\", \"#00843D\")\n","draw_box(ax, 11.5, y2, 2.2, 1.0, \"Stage 4: Clean\",\n","         \"Cross-type dedup\\n+ type correction\", \"#E87722\")\n","\n","# Arrows: row 1 â†’ row 2\n","draw_arrow(ax, 1.75, y1, 1.4, y2 + 1.0)\n","# Arrows: within row 2\n","for x_start, x_end in [(2.5,3.1), (5.3,5.9), (8.1,8.7), (10.9,11.5)]:\n","    draw_arrow(ax, x_start, y2+0.5, x_end, y2+0.5)\n","\n","# â”€â”€ Row 3: Backend Components (y ~ 2.0) â”€â”€\n","y3 = 2.0\n","draw_box(ax, 0.5, y3, 3.0, 1.2, \"Knowledge Graph\",\n","         f\"{G.number_of_nodes():,} nodes, {len(triples_df):,} triples\\n10 entity types, 11 relations\", \"#094183\")\n","draw_box(ax, 4.2, y3, 3.0, 1.2, \"Vector Store\",\n","         f\"{len(source_chunks)} evidence chunks\\nChromaDB + MiniLM-L6\", \"#6B2D5B\")\n","draw_box(ax, 7.9, y3, 3.0, 1.2, \"Query Engine\",\n","         \"4 structured query types\\n+ free-form RAG\", \"#00843D\")\n","draw_box(ax, 11.6, y3, 3.0, 1.2, \"Claude Sonnet\",\n","         \"Evidence-grounded\\nnatural language answers\", \"#E87722\")\n","\n","# Arrow: Stage 4 â†’ KG\n","draw_arrow(ax, 12.6, y2, 2.0, y3 + 1.2, colour=\"#888888\")\n","\n","# Arrows: within row 3\n","draw_arrow(ax, 3.5, y3+0.6, 4.2, y3+0.6, label=\"evidence\\nretrieval\")\n","draw_arrow(ax, 7.2, y3+0.6, 7.9, y3+0.6, label=\"graph +\\nvector\")\n","draw_arrow(ax, 10.9, y3+0.6, 11.6, y3+0.6, label=\"context +\\nquery\")\n","\n","# â”€â”€ Row 4: Query Types (y ~ 0.3) â”€â”€\n","y4 = 0.3\n","qw = 3.2\n","draw_box(ax, 0.3, y4, qw, 0.7, \"Governance Pathways\", colour=\"#094183\", alpha=0.08)\n","draw_box(ax, 4.0, y4, qw, 0.7, \"Jurisdiction Comparison\", colour=\"#094183\", alpha=0.08)\n","draw_box(ax, 7.7, y4, qw, 0.7, \"Gap Analysis\", colour=\"#094183\", alpha=0.08)\n","draw_box(ax, 11.4, y4, qw, 0.7, \"Entity Explorer\", colour=\"#094183\", alpha=0.08)\n","\n","# Arrows: query engine â†’ query types\n","for xc in [1.9, 5.6, 9.3, 13.0]:\n","    draw_arrow(ax, 9.4, y3, xc, y4 + 0.7, colour=\"#BBBBBB\")\n","\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig1_architecture.png\"))\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig1_architecture.pdf\"))\n","plt.show()\n","print(\"âœ… Figure 1 saved: fig1_architecture.png / .pdf\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Figure 1 saved: fig1_architecture.png / .pdf\n"]}],"execution_count":5,"id":"2BodkWEvuu8S"},{"cell_type":"markdown","metadata":{"id":"DA2aGvVfuu8S"},"source":["## 3) Entityâ€“relationship schema diagram\n","Designed diagram of the 10 entity types with their primary relationships,\n","showing the governance ontology used across all countries.\n","\n","**Paper reference: Figure 2.**\n"],"id":"DA2aGvVfuu8S"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDQMz8d7uu8S","executionInfo":{"status":"ok","timestamp":1770943980087,"user_tz":-660,"elapsed":740,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"3ec95ee5-844c-4d79-87e7-d3f684a86829"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 3) Entityâ€“relationship schema\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","fig, ax = plt.subplots(figsize=(14, 10))\n","ax.set_xlim(0, 14)\n","ax.set_ylim(0, 10)\n","ax.set_aspect(\"equal\")\n","ax.axis(\"off\")\n","\n","ax.text(7, 9.5, \"Governance Knowledge Graph Schema\",\n","        ha=\"center\", va=\"center\", fontsize=15, fontweight=\"bold\", color=\"#094183\")\n","ax.text(7, 9.1, \"Entity types and primary relationships\",\n","        ha=\"center\", va=\"center\", fontsize=10, color=\"#666666\")\n","\n","# Node positions (hand-tuned for readability)\n","positions = {\n","    \"Authority\":     (2.0, 7.5),\n","    \"Instrument\":    (6.0, 7.5),\n","    \"Jurisdiction\":  (10.5, 7.5),\n","    \"Requirement\":   (10.5, 5.5),\n","    \"Practice\":      (6.0, 5.0),\n","    \"Enabler\":       (2.0, 5.0),\n","    \"Barrier\":       (2.0, 2.5),\n","    \"Stakeholder\":   (5.0, 2.5),\n","    \"MaterialAsset\": (8.5, 2.5),\n","    \"OutcomeMetric\": (11.5, 3.5),\n","}\n","\n","# Draw entity-type boxes\n","for etype, (x, y) in positions.items():\n","    colour = COLOURS[etype]\n","    count = len(nodes_df[nodes_df[\"entity_type\"] == etype])\n","    box = FancyBboxPatch((x - 1.2, y - 0.45), 2.4, 0.9,\n","                          boxstyle=\"round,pad=0.12\",\n","                          facecolor=colour, alpha=0.18,\n","                          edgecolor=colour, linewidth=2)\n","    ax.add_patch(box)\n","    ax.text(x, y + 0.1, etype, ha=\"center\", va=\"center\",\n","            fontsize=9, fontweight=\"bold\", color=colour)\n","    ax.text(x, y - 0.2, f\"n = {count}\", ha=\"center\", va=\"center\",\n","            fontsize=7.5, color=\"#666666\")\n","\n","# Key relationships: (source_type, target_type, label, curvature)\n","relations = [\n","    (\"Authority\",    \"Instrument\",    \"ISSUED_BY\",    0),\n","    (\"Instrument\",   \"Jurisdiction\",  \"APPLIES_IN\",   0),\n","    (\"Instrument\",   \"Requirement\",   \"REQUIRES\",     0),\n","    (\"Instrument\",   \"Practice\",      \"ENABLES\",      0.1),\n","    (\"Enabler\",      \"Practice\",      \"ENABLES\",      0),\n","    (\"Barrier\",      \"Practice\",      \"BARRIERS\",     0),\n","    (\"Practice\",     \"OutcomeMetric\", \"PRODUCES\",     0),\n","    (\"Practice\",     \"MaterialAsset\", \"INVOLVES\",     0),\n","    (\"Stakeholder\",  \"Practice\",      \"INVOLVES\",     0),\n","    (\"Instrument\",   \"Practice\",      \"PROHIBITS\",   -0.15),\n","    (\"Requirement\",  \"Practice\",      \"APPLIES_TO\",   0.15),\n","]\n","\n","for src, tgt, label, curve in relations:\n","    x1, y1 = positions[src]\n","    x2, y2 = positions[tgt]\n","    dx, dy = x2 - x1, y2 - y1\n","    dist = np.sqrt(dx**2 + dy**2)\n","    if dist > 0:\n","        ux, uy = dx / dist, dy / dist\n","        x1s, y1s = x1 + ux * 1.3, y1 + uy * 0.5\n","        x2s, y2s = x2 - ux * 1.3, y2 - uy * 0.5\n","    else:\n","        x1s, y1s, x2s, y2s = x1, y1, x2, y2\n","\n","    style = f\"arc3,rad={curve}\" if curve else \"arc3,rad=0\"\n","    ax.annotate(\"\", xy=(x2s, y2s), xytext=(x1s, y1s),\n","                arrowprops=dict(arrowstyle=\"-|>\", color=\"#888888\", lw=1.2,\n","                                connectionstyle=style))\n","    mx = (x1s + x2s) / 2 + curve * 1.5\n","    my = (y1s + y2s) / 2 + 0.15\n","    ax.text(mx, my, label, ha=\"center\", va=\"center\", fontsize=6.5,\n","            color=\"#555555\", style=\"italic\",\n","            bbox=dict(boxstyle=\"round,pad=0.08\", facecolor=\"white\",\n","                      edgecolor=\"none\", alpha=0.85))\n","\n","# Country badge\n","ax.text(12.5, 0.5, \"Country: AU\", ha=\"center\", va=\"center\", fontsize=8,\n","        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#094183\", alpha=0.1,\n","                  edgecolor=\"#094183\"),\n","        color=\"#094183\", fontweight=\"bold\")\n","ax.text(12.5, 0.1, \"(UK, CA: same schema)\", ha=\"center\", va=\"center\",\n","        fontsize=7, color=\"#888888\")\n","\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig2_schema.png\"))\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig2_schema.pdf\"))\n","plt.show()\n","print(\"âœ… Figure 2 saved: fig2_schema.png / .pdf\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Figure 2 saved: fig2_schema.png / .pdf\n"]}],"execution_count":6,"id":"aDQMz8d7uu8S"},{"cell_type":"markdown","metadata":{"id":"L1FfGkOnuu8T"},"source":["## 4) Summary statistics dashboard\n","Composite 4-panel figure: entity types, relation types, degree distribution, platform metrics.\n","\n","**Paper reference: Figure 3.**\n"],"id":"L1FfGkOnuu8T"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJvxGx84uu8T","executionInfo":{"status":"ok","timestamp":1770943986079,"user_tz":-660,"elapsed":2288,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"efda05f1-d3d5-4e32-b8db-ac214e050878"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 7) Summary statistics dashboard\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n","fig.suptitle(\"Governance Intelligence Platform â€” Summary Statistics\",\n","             fontsize=14, fontweight=\"bold\", color=\"#094183\", y=0.98)\n","\n","# â”€â”€ Panel A: Entity type distribution â”€â”€\n","ax = axes[0, 0]\n","type_counts = nodes_df[\"entity_type\"].value_counts().reindex(ENTITY_ORDER).fillna(0).astype(int)\n","colours_ordered = [COLOURS[t] for t in ENTITY_ORDER]\n","bars = ax.barh(ENTITY_ORDER, type_counts.values, color=colours_ordered, alpha=0.7)\n","ax.set_xlabel(\"Count\")\n","ax.set_title(\"(a) Entity Type Distribution\", fontsize=11, fontweight=\"bold\")\n","ax.invert_yaxis()\n","for bar, count in zip(bars, type_counts.values):\n","    ax.text(bar.get_width() + 3, bar.get_y() + bar.get_height() / 2,\n","            str(count), va=\"center\", fontsize=8, color=\"#444444\")\n","\n","# â”€â”€ Panel B: Relation type distribution â”€â”€\n","ax = axes[0, 1]\n","rel_counts = edges_df[\"predicate\"].value_counts()\n","ax.barh(rel_counts.index, rel_counts.values, color=\"#094183\", alpha=0.5)\n","ax.set_xlabel(\"Count\")\n","ax.set_title(\"(b) Relation Type Distribution\", fontsize=11, fontweight=\"bold\")\n","ax.invert_yaxis()\n","ax.tick_params(axis=\"y\", labelsize=8)\n","for i, (idx, count) in enumerate(rel_counts.items()):\n","    ax.text(count + 3, i, str(count), va=\"center\", fontsize=7, color=\"#444444\")\n","\n","# â”€â”€ Panel C: Degree distribution (log-scale) â”€â”€\n","ax = axes[1, 0]\n","degrees = [G.degree(n) for n in G.nodes()]\n","ax.hist(degrees, bins=50, color=\"#094183\", alpha=0.6, edgecolor=\"white\")\n","ax.set_xlabel(\"Node Degree\")\n","ax.set_ylabel(\"Frequency\")\n","ax.set_title(\"(c) Degree Distribution\", fontsize=11, fontweight=\"bold\")\n","ax.set_yscale(\"log\")\n","mean_deg = np.mean(degrees)\n","ax.axvline(mean_deg, color=\"#C4262E\", linestyle=\"--\", linewidth=1,\n","           label=f\"Mean = {mean_deg:.1f}\")\n","ax.legend(fontsize=8)\n","\n","# â”€â”€ Panel D: Platform summary metrics â”€â”€\n","ax = axes[1, 1]\n","ax.axis(\"off\")\n","\n","source_files = set()\n","for chunk in source_chunks:\n","    sf = chunk.get(\"source_file\", chunk.get(\"filename\", \"\"))\n","    if sf:\n","        source_files.add(sf)\n","\n","comps = list(nx.weakly_connected_components(G))\n","largest_comp = max(comps, key=len)\n","\n","metrics = [\n","    (\"Source documents\",       f\"{len(source_files)}\"),\n","    (\"Source chunks (kept)\",   f\"{len(source_chunks)}\"),\n","    (\"Entities (nodes)\",       f\"{G.number_of_nodes():,}\"),\n","    (\"Relationships (edges)\",  f\"{G.number_of_edges():,}\"),\n","    (\"Unique triples\",         f\"{len(triples_df):,}\"),\n","    (\"Entity types\",           \"10\"),\n","    (\"Relation types\",         \"11\"),\n","    (\"Graph components\",       f\"{len(comps)}\"),\n","    (\"Largest component\",      f\"{len(largest_comp):,} ({100*len(largest_comp)/G.number_of_nodes():.0f}%)\"),\n","    (\"Countries (current)\",    \"AU\"),\n","    (\"Countries (planned)\",    \"AU, UK, CA\"),\n","    (\"LLM pipeline\",           \"Haiku â†’ Sonnet â†’ Sonnet\"),\n","    (\"Vector store\",           f\"{len(source_chunks)} chunks (MiniLM-L6)\"),\n","    (\"Query types\",            \"4 structured + free-form\"),\n","]\n","\n","for i, (label, value) in enumerate(metrics):\n","    y = 0.95 - i * 0.068\n","    ax.text(0.05, y, label, fontsize=9, color=\"#666666\",\n","            transform=ax.transAxes, va=\"center\")\n","    ax.text(0.65, y, value, fontsize=9, fontweight=\"bold\", color=\"#094183\",\n","            transform=ax.transAxes, va=\"center\")\n","\n","ax.set_title(\"(d) Platform Metrics\", fontsize=11, fontweight=\"bold\")\n","\n","plt.tight_layout(rect=[0, 0, 1, 0.95])\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig3_dashboard.png\"))\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig3_dashboard.pdf\"))\n","plt.show()\n","print(\"âœ… Figure 6 saved: fig3_dashboard.png / .pdf\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Figure 6 saved: fig3_dashboard.png / .pdf\n"]}],"execution_count":7,"id":"cJvxGx84uu8T"},{"cell_type":"markdown","metadata":{"id":"3g5adNiVuu8S"},"source":["## 5) Governance pathway visualisation\n","A focused subgraph showing the governance pathway for Design for Disassembly (DfD):\n","instruments, requirements, barriers, enablers, and outcomes connected to DfD.\n","\n","Capped at 5 neighbours per entity type for readability.\n","\n","**Paper reference: Figure 4.**\n"],"id":"3g5adNiVuu8S"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBohtdHDuu8S","executionInfo":{"status":"ok","timestamp":1770943996000,"user_tz":-660,"elapsed":2011,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"892ba4a2-08d5-45ac-ae7c-141bc28341c8"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 4) DfD governance pathway subgraph\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","# Find DfD node (highest-degree Practice with \"disassembly\" in name)\n","dfd_id = None\n","best_deg = 0\n","for nid, data in G.nodes(data=True):\n","    if \"disassembly\" in data.get(\"name\", \"\").lower() and data.get(\"entity_type\") == \"Practice\":\n","        deg = G.degree(nid)\n","        if deg > best_deg:\n","            best_deg = deg\n","            dfd_id = nid\n","\n","if not dfd_id:\n","    print(\"âš  DfD node not found â€” skipping this figure.\")\n","else:\n","    dfd_name = G.nodes[dfd_id].get(\"name\", \"DfD\")\n","    print(f\"DfD node: '{dfd_name}' (degree {best_deg})\")\n","\n","    # Collect all 1-hop neighbours with edge info\n","    neighbours = []\n","    seen = set()\n","    for _, tgt, data in G.out_edges(dfd_id, data=True):\n","        key = (tgt, data.get(\"predicate\", \"\"))\n","        if key not in seen:\n","            seen.add(key)\n","            neighbours.append({\"id\": tgt, \"pred\": data.get(\"predicate\", \"\"), \"dir\": \"out\"})\n","    for src, _, data in G.in_edges(dfd_id, data=True):\n","        key = (src, data.get(\"predicate\", \"\"))\n","        if key not in seen:\n","            seen.add(key)\n","            neighbours.append({\"id\": src, \"pred\": data.get(\"predicate\", \"\"), \"dir\": \"in\"})\n","\n","    # Cap at 5 per entity type, prioritised by degree\n","    MAX_PER_TYPE = 5\n","    type_buckets = defaultdict(list)\n","    for n in neighbours:\n","        etype = G.nodes[n[\"id\"]].get(\"entity_type\", \"Unknown\")\n","        type_buckets[etype].append(n)\n","\n","    keep = []\n","    for etype, bucket in type_buckets.items():\n","        bucket.sort(key=lambda x: -G.degree(x[\"id\"]))\n","        keep.extend(bucket[:MAX_PER_TYPE])\n","\n","    # Build filtered subgraph\n","    sub = nx.DiGraph()\n","    sub.add_node(dfd_id, **dict(G.nodes[dfd_id]))\n","    for n in keep:\n","        sub.add_node(n[\"id\"], **dict(G.nodes[n[\"id\"]]))\n","        if n[\"dir\"] == \"out\":\n","            sub.add_edge(dfd_id, n[\"id\"], predicate=n[\"pred\"])\n","        else:\n","            sub.add_edge(n[\"id\"], dfd_id, predicate=n[\"pred\"])\n","\n","    print(f\"Subgraph: {sub.number_of_nodes()} nodes, {sub.number_of_edges()} edges\")\n","    print(f\"Types: {Counter(sub.nodes[n].get('entity_type','') for n in sub.nodes if n != dfd_id)}\")\n","\n","    # Layout: use spring with DfD pinned at centre\n","    pos = nx.spring_layout(sub, seed=42, k=2.8, iterations=100,\n","                            pos={dfd_id: (0, 0)}, fixed=[dfd_id])\n","\n","    # Draw\n","    fig, ax = plt.subplots(figsize=(16, 11))\n","\n","    # Edges\n","    for u, v, data in sub.edges(data=True):\n","        x1, y1 = pos[u]\n","        x2, y2 = pos[v]\n","        pred = data.get(\"predicate\", \"\")\n","        ax.annotate(\"\", xy=(x2, y2), xytext=(x1, y1),\n","                    arrowprops=dict(arrowstyle=\"-|>\", color=\"#CCCCCC\", lw=0.8,\n","                                    shrinkA=15, shrinkB=15))\n","        mx, my = (x1 + x2) / 2, (y1 + y2) / 2\n","        ax.text(mx, my + 0.02, pred, fontsize=5, ha=\"center\", va=\"center\",\n","                color=\"#999999\", style=\"italic\")\n","\n","    # Nodes\n","    for nid in sub.nodes():\n","        x, y = pos[nid]\n","        nd = sub.nodes[nid]\n","        etype = nd.get(\"entity_type\", \"\")\n","        name = nd.get(\"name\", \"\")\n","        colour = COLOURS.get(etype, \"#888888\")\n","\n","        if nid == dfd_id:\n","            ax.scatter(x, y, s=1200, c=colour, alpha=0.25, zorder=2,\n","                       edgecolors=colour, linewidths=2.5)\n","            ax.text(x, y, textwrap.fill(name, 22), ha=\"center\", va=\"center\",\n","                    fontsize=9, fontweight=\"bold\", color=colour, zorder=3)\n","        else:\n","            ax.scatter(x, y, s=500, c=colour, alpha=0.18, zorder=2,\n","                       edgecolors=colour, linewidths=1)\n","            label = name if len(name) < 35 else name[:32] + \"â€¦\"\n","            ax.text(x, y, textwrap.fill(label, 24), ha=\"center\", va=\"center\",\n","                    fontsize=6.5, color=colour, zorder=3)\n","\n","    # Legend\n","    types_present = set(sub.nodes[n].get(\"entity_type\",\"\") for n in sub.nodes())\n","    legend_handles = [mpatches.Patch(color=COLOURS.get(t,\"#888\"), alpha=0.5, label=t)\n","                      for t in ENTITY_ORDER if t in types_present]\n","    ax.legend(handles=legend_handles, loc=\"upper left\", fontsize=8, framealpha=0.9)\n","\n","    ax.set_title(f\"Governance Pathway: {dfd_name} â€” 1-Hop Ego Network\",\n","                 fontsize=13, fontweight=\"bold\", color=\"#094183\", pad=15)\n","    ax.axis(\"off\")\n","\n","    fig.savefig(os.path.join(OUTPUT_DIR, \"fig4_dfd_pathway.png\"))\n","    fig.savefig(os.path.join(OUTPUT_DIR, \"fig4_dfd_pathway.pdf\"))\n","    plt.show()\n","    print(f\"âœ… Figure 3 saved: fig4_dfd_pathway.png / .pdf ({sub.number_of_nodes()} nodes)\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["DfD node: 'Design for Disassembly (DfD)' (degree 133)\n","Subgraph: 34 nodes, 33 edges\n","Types: Counter({'Practice': 5, 'Stakeholder': 5, 'Requirement': 4, 'Instrument': 4, 'Enabler': 4, 'OutcomeMetric': 3, 'MaterialAsset': 3, 'Authority': 3, 'Barrier': 2})\n","âœ… Figure 3 saved: fig4_dfd_pathway.png / .pdf (34 nodes)\n"]}],"execution_count":8,"id":"cBohtdHDuu8S"},{"cell_type":"markdown","metadata":{"id":"RIIsYbJfuu8S"},"source":["## 6) Jurisdictional coverage heatmap\n","Matrix showing which entities connect to which Australian jurisdictions,\n","based on all edges linking to Jurisdiction-typed nodes.\n","\n","Since most instruments in the corpus are tagged to \"Australia\" broadly rather than\n","to individual states, this figure uses *all entity types* connected to jurisdictions\n","to give the most informative comparison.\n","\n","**Paper reference: Figure 5.**\n"],"id":"RIIsYbJfuu8S"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vp0RxtmOuu8S","executionInfo":{"status":"ok","timestamp":1770944005608,"user_tz":-660,"elapsed":2700,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"24037ed0-4269-4fc3-abb8-dd28a718f4cf"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 5) Jurisdictional coverage heatmap\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","# Identify jurisdiction nodes\n","jur_ids = nodes_df[nodes_df[\"entity_type\"] == \"Jurisdiction\"][\"node_id\"].tolist()\n","jur_name_map = {row[\"node_id\"]: row[\"name\"]\n","                for _, row in nodes_df[nodes_df[\"entity_type\"] == \"Jurisdiction\"].iterrows()}\n","\n","# Collect ALL edges involving a jurisdiction node (in either direction)\n","jur_links = []\n","for jid in jur_ids:\n","    jname = jur_name_map[jid]\n","    # Outgoing from jurisdiction\n","    for _, tgt, data in G.out_edges(jid, data=True):\n","        tgt_data = G.nodes[tgt]\n","        jur_links.append({\n","            \"jurisdiction\": jname,\n","            \"entity\": tgt_data.get(\"name\", \"\"),\n","            \"entity_type\": tgt_data.get(\"entity_type\", \"\"),\n","            \"predicate\": data.get(\"predicate\", \"\"),\n","        })\n","    # Incoming to jurisdiction\n","    for src, _, data in G.in_edges(jid, data=True):\n","        src_data = G.nodes[src]\n","        jur_links.append({\n","            \"jurisdiction\": jname,\n","            \"entity\": src_data.get(\"name\", \"\"),\n","            \"entity_type\": src_data.get(\"entity_type\", \"\"),\n","            \"predicate\": data.get(\"predicate\", \"\"),\n","        })\n","\n","jur_df = pd.DataFrame(jur_links).drop_duplicates(subset=[\"jurisdiction\", \"entity\"])\n","print(f\"Jurisdiction links: {len(jur_df)} unique (jurisdiction, entity) pairs\")\n","print(f\"Jurisdictions: {sorted(jur_df['jurisdiction'].unique())}\")\n","\n","# â”€â”€ Panel A: Count of entity types per jurisdiction â”€â”€\n","fig, axes = plt.subplots(1, 2, figsize=(16, 8), gridspec_kw={\"width_ratios\": [1.3, 1]})\n","\n","# Left panel: stacked bar chart\n","ax = axes[0]\n","pivot = jur_df.groupby([\"jurisdiction\", \"entity_type\"]).size().unstack(fill_value=0)\n","# Sort jurisdictions by total connections\n","pivot = pivot.loc[pivot.sum(axis=1).sort_values(ascending=True).index]\n","# Reorder columns to entity order\n","cols_present = [c for c in ENTITY_ORDER if c in pivot.columns]\n","cols_other = [c for c in pivot.columns if c not in cols_present]\n","pivot = pivot[cols_present + cols_other]\n","\n","pivot.plot(kind=\"barh\", stacked=True, ax=ax,\n","           color=[COLOURS.get(c, \"#888888\") for c in pivot.columns],\n","           alpha=0.75, edgecolor=\"white\", linewidth=0.5)\n","\n","ax.set_xlabel(\"Number of connected entities\", fontsize=10)\n","ax.set_ylabel(\"\")\n","ax.set_title(\"(a) Entity Connections by Jurisdiction\", fontsize=11, fontweight=\"bold\", color=\"#094183\")\n","ax.legend(bbox_to_anchor=(0, -0.15), loc=\"upper left\", ncol=3, fontsize=7, framealpha=0.9)\n","ax.tick_params(axis=\"y\", labelsize=8)\n","\n","# Add count labels\n","for container in ax.containers:\n","    for bar in container:\n","        w = bar.get_width()\n","        if w > 2:\n","            ax.text(bar.get_x() + w / 2, bar.get_y() + bar.get_height() / 2,\n","                    str(int(w)), ha=\"center\", va=\"center\", fontsize=6, color=\"white\",\n","                    fontweight=\"bold\")\n","\n","# â”€â”€ Panel B: Instrument Ã— Jurisdiction binary heatmap (APPLIES_IN only) â”€â”€\n","ax = axes[1]\n","\n","applies_in_only = jur_df[jur_df[\"predicate\"] == \"APPLIES_IN\"].copy()\n","if len(applies_in_only) > 5:\n","    # Instrument-type entities only\n","    inst_links = applies_in_only[applies_in_only[\"entity_type\"] == \"Instrument\"]\n","    if len(inst_links) > 0:\n","        matrix = pd.crosstab(inst_links[\"entity\"], inst_links[\"jurisdiction\"])\n","        matrix = matrix.loc[matrix.sum(axis=1).sort_values(ascending=False).index]\n","        matrix = matrix[matrix.sum().sort_values(ascending=False).index]\n","        TOP = min(25, len(matrix))\n","        matrix = matrix.head(TOP)\n","\n","        sns.heatmap(matrix, annot=False, cmap=\"YlOrRd\", linewidths=0.5,\n","                    linecolor=\"white\", cbar_kws={\"label\": \"Coverage\"},\n","                    ax=ax, vmin=0, vmax=1)\n","        ax.set_title(\"(b) Instrument Ã— Jurisdiction\", fontsize=11, fontweight=\"bold\", color=\"#094183\")\n","        ax.tick_params(axis=\"y\", labelsize=6)\n","        ax.tick_params(axis=\"x\", labelsize=7)\n","        plt.sca(ax)\n","        plt.xticks(rotation=45, ha=\"right\")\n","    else:\n","        # Fall back: all entity types in APPLIES_IN\n","        matrix = pd.crosstab(applies_in_only[\"entity\"], applies_in_only[\"jurisdiction\"])\n","        matrix = matrix.loc[matrix.sum(axis=1).sort_values(ascending=False).index].head(25)\n","        sns.heatmap(matrix, annot=False, cmap=\"YlOrRd\", linewidths=0.5,\n","                    linecolor=\"white\", ax=ax, vmin=0, vmax=1)\n","        ax.set_title(\"(b) Entities Ã— Jurisdiction (APPLIES_IN)\", fontsize=11, fontweight=\"bold\", color=\"#094183\")\n","        ax.tick_params(axis=\"y\", labelsize=6)\n","        plt.sca(ax)\n","        plt.xticks(rotation=45, ha=\"right\")\n","else:\n","    # Fall back: use all edges\n","    matrix = pd.crosstab(jur_df[\"entity\"], jur_df[\"jurisdiction\"])\n","    matrix = matrix.loc[matrix.sum(axis=1).sort_values(ascending=False).index].head(25)\n","    sns.heatmap(matrix, annot=False, cmap=\"YlOrRd\", linewidths=0.5,\n","                linecolor=\"white\", ax=ax, vmin=0, vmax=1)\n","    ax.set_title(\"(b) Top Entities Ã— Jurisdiction (all edges)\", fontsize=11, fontweight=\"bold\", color=\"#094183\")\n","    ax.tick_params(axis=\"y\", labelsize=6)\n","    plt.sca(ax)\n","    plt.xticks(rotation=45, ha=\"right\")\n","\n","plt.tight_layout()\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig5_jurisdiction_heatmap.png\"))\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig5_jurisdiction_heatmap.pdf\"))\n","plt.show()\n","print(f\"âœ… Figure 4 saved: fig5_jurisdiction_heatmap.png / .pdf\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["Jurisdiction links: 170 unique (jurisdiction, entity) pairs\n","Jurisdictions: ['AEC industry', 'Australia', 'Australian Cities', 'Australian States and Territories', 'Belgium', 'Brussels', 'Bulli community', 'China', 'Construction Sites', 'Denmark', 'EU', 'Education sector', 'Erith', 'Europe', 'Finland', 'France', 'Germany', 'Government Projects', 'Ireland', 'Japan', 'Leuven', 'Local Government Areas (LGAs)', 'London', 'National Level', 'Netherlands', 'New South Wales (NSW)', 'Northern Territory (NT)', 'Olympic and Paralympic Games', 'Portugal', 'QLD', 'Regional Development', 'Scotland', 'Slovenia', 'Sri Lanka', 'Sweden', 'The Cape', 'United Kingdom (UK)', 'United States (USA)', 'Victoria', 'Western Australia']\n","âœ… Figure 4 saved: fig5_jurisdiction_heatmap.png / .pdf\n"]}],"execution_count":9,"id":"vp0RxtmOuu8S"},{"cell_type":"markdown","metadata":{"id":"cCenjXqzuu8S"},"source":["## 7) Gap analysis matrix\n","Visualises the governance gaps: practices with barriers but lacking\n","enabling instruments or policy support. Practices with zero instruments/enablers\n","are highlighted in red (high-severity gaps).\n","\n","**Paper reference: Figure 6.**\n"],"id":"cCenjXqzuu8S"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OBMvVGjuu8S","executionInfo":{"status":"ok","timestamp":1770944011314,"user_tz":-660,"elapsed":1386,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"c0fbd119-6a65-4a31-d33f-c42443cebe2c"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 6) Gap analysis matrix\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","practice_nodes = nodes_df[nodes_df[\"entity_type\"] == \"Practice\"]\n","\n","gap_data = []\n","for _, row in practice_nodes.iterrows():\n","    pid = row[\"node_id\"]\n","    name = row[\"name\"]\n","\n","    barriers = set()\n","    instruments = set()\n","    enablers = set()\n","\n","    # Check both directions for connections\n","    for src, _, data in G.in_edges(pid, data=True):\n","        stype = G.nodes[src].get(\"entity_type\", \"\")\n","        sname = G.nodes[src].get(\"name\", \"\")\n","        if stype == \"Barrier\":      barriers.add(sname)\n","        elif stype == \"Instrument\": instruments.add(sname)\n","        elif stype == \"Enabler\":    enablers.add(sname)\n","\n","    for _, tgt, data in G.out_edges(pid, data=True):\n","        ttype = G.nodes[tgt].get(\"entity_type\", \"\")\n","        tname = G.nodes[tgt].get(\"name\", \"\")\n","        if ttype == \"Barrier\":      barriers.add(tname)\n","        elif ttype == \"Instrument\": instruments.add(tname)\n","        elif ttype == \"Enabler\":    enablers.add(tname)\n","\n","    if barriers:\n","        support = len(instruments) + len(enablers)\n","        gap_data.append({\n","            \"practice\": name,\n","            \"n_barriers\": len(barriers),\n","            \"n_instruments\": len(instruments),\n","            \"n_enablers\": len(enablers),\n","            \"n_support\": support,\n","            \"gap_severity\": \"HIGH\" if support == 0 else (\"MEDIUM\" if len(barriers) > support else \"LOW\"),\n","            \"gap_ratio\": len(barriers) / max(1, support),\n","        })\n","\n","gap_df = pd.DataFrame(gap_data).sort_values(\n","    [\"gap_severity\", \"gap_ratio\", \"n_barriers\"],\n","    ascending=[True, False, False]\n",")\n","\n","TOP_GAPS = min(30, len(gap_df))\n","plot_df = gap_df.head(TOP_GAPS).copy().reset_index(drop=True)\n","\n","fig, ax = plt.subplots(figsize=(12, max(7, TOP_GAPS * 0.38)))\n","\n","y_pos = np.arange(len(plot_df))\n","bar_h = 0.38\n","\n","# Barriers (red bars)\n","ax.barh(y_pos - bar_h/2, plot_df[\"n_barriers\"], height=bar_h,\n","        color=\"#C4262E\", alpha=0.7, label=\"Barriers\", zorder=2)\n","\n","# Instruments + Enablers (green bars)\n","ax.barh(y_pos + bar_h/2, plot_df[\"n_support\"], height=bar_h,\n","        color=\"#2EAF7D\", alpha=0.7, label=\"Instruments + Enablers\", zorder=2)\n","\n","ax.set_yticks(y_pos)\n","ax.set_yticklabels(plot_df[\"practice\"], fontsize=7)\n","ax.invert_yaxis()\n","ax.set_xlabel(\"Count\", fontsize=10)\n","ax.set_title(\"Governance Gap Analysis: Barriers vs. Policy Support by Practice\",\n","             fontsize=13, fontweight=\"bold\", color=\"#094183\", pad=15)\n","ax.legend(loc=\"lower right\", fontsize=9, framealpha=0.9)\n","ax.axvline(x=0, color=\"black\", linewidth=0.5)\n","\n","# Highlight high-severity gaps\n","for i, sev in enumerate(plot_df[\"gap_severity\"]):\n","    if sev == \"HIGH\":\n","        ax.get_yticklabels()[i].set_color(\"#C4262E\")\n","        ax.get_yticklabels()[i].set_fontweight(\"bold\")\n","\n","# Severity legend\n","n_high = len(gap_df[gap_df[\"gap_severity\"] == \"HIGH\"])\n","n_med = len(gap_df[gap_df[\"gap_severity\"] == \"MEDIUM\"])\n","n_low = len(gap_df[gap_df[\"gap_severity\"] == \"LOW\"])\n","ax.text(0.98, 0.02,\n","        f\"HIGH severity (0 support): {n_high}\\nMEDIUM: {n_med}  |  LOW: {n_low}\\n\"\n","        f\"Total practices with barriers: {len(gap_df)} / {len(practice_nodes)}\",\n","        transform=ax.transAxes, fontsize=8, va=\"bottom\", ha=\"right\",\n","        bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"#f8f8f8\", edgecolor=\"#cccccc\"))\n","\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig6_gap_analysis.png\"))\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig6_gap_analysis.pdf\"))\n","plt.show()\n","print(f\"âœ… Figure 5 saved: fig6_gap_analysis.png / .pdf ({TOP_GAPS} practices shown)\")\n","print(f\"   High-severity gaps: {n_high} | Medium: {n_med} | Low: {n_low}\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Figure 5 saved: fig6_gap_analysis.png / .pdf (30 practices shown)\n","   High-severity gaps: 29 | Medium: 4 | Low: 19\n"]}],"execution_count":10,"id":"6OBMvVGjuu8S"},{"cell_type":"markdown","metadata":{"id":"HFFIYQqIuu8T"},"source":["## 8) Demo Q&A cards (formatted for slides)\n","Extracts key excerpts from each demo answer and formats them as\n","presentation-ready text panels â€” one per query type.\n","\n","**Paper reference: Figure 7.**\n"],"id":"HFFIYQqIuu8T"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MfWZHP9Suu8T","executionInfo":{"status":"ok","timestamp":1770944015464,"user_tz":-660,"elapsed":1329,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"afde36e3-970c-43fb-94c0-12375b5c9281"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 8) Demo Q&A cards\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","card_configs = [\n","    {\n","        \"key\": \"demo_1_dfd_pathway\",\n","        \"title\": \"Governance Pathway Query\",\n","        \"icon\": \"Q1\",\n","        \"question\": \"What instruments govern Design for\\nDisassembly (DfD) in Australia?\",\n","        \"colour\": \"#094183\",\n","    },\n","    {\n","        \"key\": \"demo_2_jurisdiction_comparison\",\n","        \"title\": \"Jurisdictional Comparison\",\n","        \"icon\": \"Q2\",\n","        \"question\": \"How do VIC, NSW, and QLD compare\\nin circular economy instruments?\",\n","        \"colour\": \"#0E6EB8\",\n","    },\n","    {\n","        \"key\": \"demo_3_gap_analysis\",\n","        \"title\": \"Gap Analysis\",\n","        \"icon\": \"Q3\",\n","        \"question\": \"Which practices face barriers without\\nenabling policy support?\",\n","        \"colour\": \"#C4262E\",\n","    },\n","    {\n","        \"key\": \"demo_4_free_query\",\n","        \"title\": \"Evidence-Grounded Q&A\",\n","        \"icon\": \"Q4\",\n","        \"question\": \"How do material passports support\\nbuilding deconstruction in Australia?\",\n","        \"colour\": \"#00843D\",\n","    },\n","]\n","\n","fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n","fig.suptitle(\"Query Demonstrations â€” Governance Intelligence Platform\",\n","             fontsize=14, fontweight=\"bold\", color=\"#094183\", y=0.98)\n","\n","for ax, config in zip(axes.flat, card_configs):\n","    ax.set_xlim(0, 10)\n","    ax.set_ylim(0, 10)\n","    ax.axis(\"off\")\n","    colour = config[\"colour\"]\n","\n","    # Card border\n","    border = FancyBboxPatch((0.2, 0.2), 9.6, 9.6,\n","                             boxstyle=\"round,pad=0.3\",\n","                             facecolor=\"white\", edgecolor=colour,\n","                             linewidth=2, alpha=1)\n","    ax.add_patch(border)\n","\n","    # Header bar\n","    header = FancyBboxPatch((0.3, 8.2), 9.4, 1.4,\n","                             boxstyle=\"round,pad=0.15\",\n","                             facecolor=colour, alpha=0.12, edgecolor=\"none\")\n","    ax.add_patch(header)\n","\n","    # Icon circle + title\n","    circle = plt.Circle((1.1, 8.9), 0.35, facecolor=colour, alpha=0.2, edgecolor=colour, linewidth=1.5)\n","    ax.add_patch(circle)\n","    ax.text(1.1, 8.9, config[\"icon\"], ha=\"center\", va=\"center\",\n","            fontsize=10, fontweight=\"bold\", color=colour)\n","    ax.text(1.8, 9.1, config[\"title\"],\n","            fontsize=11, fontweight=\"bold\", color=colour)\n","\n","    # Question\n","    ax.text(0.8, 8.45, config[\"question\"],\n","            fontsize=8.5, color=\"#333333\", style=\"italic\")\n","\n","    # Answer excerpt: extract first meaningful content lines\n","    answer = demos.get(config[\"key\"], {}).get(\"answer\", \"No answer available\")\n","    lines = answer.split(\"\\n\")\n","    excerpt_lines = []\n","    char_count = 0\n","    for line in lines:\n","        line = line.strip()\n","        if not line or line.startswith(\"#\"):\n","            continue\n","        line = re.sub(r\"\\*\\*(.+?)\\*\\*\", r\"\\1\", line)  # strip markdown bold\n","        line = re.sub(r\"\\*(.+?)\\*\", r\"\\1\", line)         # strip markdown italic\n","        if char_count + len(line) > 550:\n","            remaining = 550 - char_count\n","            if remaining > 40:\n","                excerpt_lines.append(line[:remaining] + \"â€¦\")\n","            break\n","        excerpt_lines.append(line)\n","        char_count += len(line)\n","        if len(excerpt_lines) >= 7:\n","            break\n","\n","    excerpt = \"\\n\".join(excerpt_lines)\n","\n","    ax.text(0.8, 7.7, \"Key Findings:\", fontsize=9, fontweight=\"bold\", color=colour)\n","    ax.text(0.8, 7.2, textwrap.fill(excerpt, 78),\n","            fontsize=6.8, color=\"#333333\", va=\"top\", linespacing=1.5)\n","\n","    # Structured data badge at bottom\n","    result = demos.get(config[\"key\"], {}).get(\"structured_result\", {})\n","    if isinstance(result, dict):\n","        counts = result.get(\"summary_counts\", result.get(\"entity_counts\", {}))\n","        if counts:\n","            badge_parts = [f\"{k}: {v}\" for k, v in list(counts.items())[:5]]\n","            badge_text = \"  |  \".join(badge_parts)\n","            ax.text(0.8, 0.65, badge_text, fontsize=6.5, color=\"#666666\",\n","                    bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"#f0f0f0\",\n","                              edgecolor=\"#cccccc\"))\n","\n","plt.tight_layout(rect=[0, 0, 1, 0.95])\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig7_demo_cards.png\"))\n","fig.savefig(os.path.join(OUTPUT_DIR, \"fig7_demo_cards.pdf\"))\n","plt.show()\n","print(\"âœ… Figure 7 saved: fig7_demo_cards.png / .pdf\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Figure 7 saved: fig7_demo_cards.png / .pdf\n"]}],"execution_count":11,"id":"MfWZHP9Suu8T"},{"cell_type":"markdown","metadata":{"id":"tMz4zC2Fuu8T"},"source":["## 9) Export all figures + manifest\n","Creates a manifest of all generated presentation materials with file sizes.\n"],"id":"tMz4zC2Fuu8T"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwfyz0Jzuu8T","executionInfo":{"status":"ok","timestamp":1770944019230,"user_tz":-660,"elapsed":22,"user":{"displayName":"M. Reza Hosseini","userId":"13449621777993109619"}},"outputId":"c88c4f57-4e38-44db-d971-8b6da87a8467"},"source":["# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 9) Export manifest\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","import glob\n","\n","all_files = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"*\")))\n","\n","manifest = {\n","    \"generated_at\": pd.Timestamp.now().isoformat(),\n","    \"output_directory\": OUTPUT_DIR,\n","    \"figures\": {},\n","    \"summary\": {},\n","}\n","\n","print(f\"{'='*60}\")\n","print(f\"STAGE 6 â€” PRESENTATION OUTPUTS\")\n","print(f\"{'='*60}\")\n","print(f\"Output directory: {OUTPUT_DIR}\\n\")\n","\n","total_size = 0\n","fig_count = 0\n","for f in all_files:\n","    fname = os.path.basename(f)\n","    size_kb = os.path.getsize(f) / 1024\n","    total_size += size_kb\n","    is_fig = fname.startswith(\"fig\")\n","    marker = \"ðŸ“Š\" if is_fig else \"ðŸ“„\"\n","    if is_fig:\n","        fig_count += 1\n","    print(f\"  {marker} {fname:45s} ({size_kb:7.1f} KB)\")\n","    manifest[\"figures\" if is_fig else \"summary\"][fname] = round(size_kb, 1)\n","\n","# Save manifest\n","manifest_path = os.path.join(OUTPUT_DIR, \"manifest.json\")\n","with open(manifest_path, \"w\") as f:\n","    json.dump(manifest, f, indent=2, default=str)\n","\n","print(f\"\\n  Total: {fig_count} figures, {total_size:.0f} KB\")\n","print(f\"  Manifest: {manifest_path}\")\n","print(f\"\\nâœ… All presentation materials ready for slides / paper.\")\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","STAGE 6 â€” PRESENTATION OUTPUTS\n","============================================================\n","Output directory: /content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/data_analysis/6_presentation\n","\n","  ðŸ“Š fig1_architecture.pdf                         (   45.6 KB)\n","  ðŸ“Š fig1_architecture.png                         (  427.3 KB)\n","  ðŸ“Š fig2_schema.pdf                               (   36.4 KB)\n","  ðŸ“Š fig2_schema.png                               (  268.3 KB)\n","  ðŸ“Š fig3_dashboard.pdf                            (   41.4 KB)\n","  ðŸ“Š fig3_dashboard.png                            (  466.2 KB)\n","  ðŸ“Š fig4_dfd_pathway.pdf                          (   44.3 KB)\n","  ðŸ“Š fig4_dfd_pathway.png                          (  956.2 KB)\n","  ðŸ“Š fig5_jurisdiction_heatmap.pdf                 (   50.0 KB)\n","  ðŸ“Š fig5_jurisdiction_heatmap.png                 (  693.7 KB)\n","  ðŸ“Š fig6_gap_analysis.pdf                         (   32.9 KB)\n","  ðŸ“Š fig6_gap_analysis.png                         (  331.8 KB)\n","  ðŸ“Š fig7_demo_cards.pdf                           (   48.8 KB)\n","  ðŸ“Š fig7_demo_cards.png                           (  767.1 KB)\n","\n","  Total: 14 figures, 4210 KB\n","  Manifest: /content/drive/MyDrive/ACTIVE/AU_deconstruction_domain/data_analysis/6_presentation/manifest.json\n","\n","âœ… All presentation materials ready for slides / paper.\n"]}],"execution_count":12,"id":"hwfyz0Jzuu8T"}]}